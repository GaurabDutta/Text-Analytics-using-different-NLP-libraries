{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from textblob) (3.5)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.50.2)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2020.10.15)\n",
      "Requirement already satisfied: click in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (0.17.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Gaurab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Gaurab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Gaurab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Gaurab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Gaurab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Gaurab\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!python -m textblob.download_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"pp\")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# indexing\n",
    "blob[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"APPLE\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upper\n",
    "blob.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.find('pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_blob = TextBlob('apple')\n",
    "b_blob = TextBlob('samsung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparision\n",
    "a_blob > b_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"apple and samsung\")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenate\n",
    "a_blob +' and '+ b_blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('natural', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('processing', 'NN'),\n",
       " ('I', 'PRP'),\n",
       " ('love', 'VBP'),\n",
       " ('to', 'TO'),\n",
       " ('study', 'VB'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos tagging\n",
    "wiki = TextBlob('I love natural language processing. I love to study data science.')\n",
    "wiki.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_cmpkey',\n",
       " '_compare',\n",
       " '_create_sentence_objects',\n",
       " '_strkey',\n",
       " 'analyzer',\n",
       " 'classifier',\n",
       " 'classify',\n",
       " 'correct',\n",
       " 'detect_language',\n",
       " 'ends_with',\n",
       " 'endswith',\n",
       " 'find',\n",
       " 'format',\n",
       " 'index',\n",
       " 'join',\n",
       " 'json',\n",
       " 'lower',\n",
       " 'ngrams',\n",
       " 'noun_phrases',\n",
       " 'np_counts',\n",
       " 'np_extractor',\n",
       " 'parse',\n",
       " 'parser',\n",
       " 'polarity',\n",
       " 'pos_tagger',\n",
       " 'pos_tags',\n",
       " 'raw',\n",
       " 'raw_sentences',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'sentences',\n",
       " 'sentiment',\n",
       " 'sentiment_assessments',\n",
       " 'serialized',\n",
       " 'split',\n",
       " 'starts_with',\n",
       " 'startswith',\n",
       " 'string',\n",
       " 'strip',\n",
       " 'stripped',\n",
       " 'subjectivity',\n",
       " 'tags',\n",
       " 'title',\n",
       " 'to_json',\n",
       " 'tokenize',\n",
       " 'tokenizer',\n",
       " 'tokens',\n",
       " 'translate',\n",
       " 'translator',\n",
       " 'upper',\n",
       " 'word_counts',\n",
       " 'words']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['natural language processing', 'data science'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# noun phrase extraction\n",
    "wiki.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['I', 'love', 'natural', 'language', 'processing', 'I', 'love', 'to', 'study', 'data', 'science'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenization\n",
    "wiki.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"I love natural language processing.\"),\n",
       " Sentence(\"I love to study data science.\")]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence tokenization\n",
    "wiki.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# singular plural\n",
    "sentence = TextBlob('Use 4 spaces per indentation level')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Use', '4', 'spaces', 'per', 'indentation', 'level'])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'space'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[2].singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'levels'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.words[5].pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indent'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stemming\n",
    "sentence.words[4].stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "a = Word('history')\n",
    "a.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'history sentence indentation histori'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = Word('history sentence indentation history')\n",
    "b.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lemmatization\n",
    "a = Word('went')\n",
    "a.lemmatize('v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the linear extent in space from one end to the other; the longest dimension of something that is fixed in place',\n",
       " 'continuance in time',\n",
       " 'the property of being the extent of something from beginning to end',\n",
       " 'size of the gap between two places',\n",
       " 'a section of something that is long and narrow']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('length').definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a collection of facts from which conclusions may be drawn',\n",
       " 'an item of factual information derived from measurement or research']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('data').definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blasphemy\n"
     ]
    }
   ],
   "source": [
    "# spelling correction\n",
    "a = TextBlob('blsphamy')\n",
    "print(a.correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('since', 0.8125), ('science', 0.1875)]\n"
     ]
    }
   ],
   "source": [
    "# spell check\n",
    "b = Word('scince')\n",
    "print(b.spellcheck())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "0\n",
      "1\n",
      "0\n",
      "2\n",
      "2\n",
      "0\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sent = TextBlob('She sells sea shells in the Sea shore')\n",
    "print(sent.word_counts['she'])\n",
    "print(sent.word_counts['She'])\n",
    "print(sent.words.count('She', case_sensitive=True))\n",
    "print(sent.words.count('she', case_sensitive=True))\n",
    "print(sent.word_counts['sea'])\n",
    "print(sent.words.count('sea'))\n",
    "print(sent.word_counts['Sea'])\n",
    "print(sent.words.count('Sea'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"कुछ नहीं से कुछ भला\")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('Something is better than nothing')\n",
    "blob.translate(to='hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"something is better than nothing\")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('कुछ नहीं से कुछ भला')\n",
    "blob.translate(to='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = TextBlob('कुछ नहीं से कुछ भला')\n",
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['bengal', 'education minister', 'partha chatterjee', 'february', 'chatterjee', 'physical classes', 'regular intervals'])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_str = '''West Bengal Education Minister Partha Chatterjee on Tuesday announced that schools for classes 9 to 12 will reopen from February 12. Chatterjee said the consent of parents would be mandatory for attending physical classes. However, he further said that students' attendance might not be compulsory, adding that schools were being thoroughly sanitised at regular intervals.''' \n",
    "blob = TextBlob(my_str)\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['West', 'Bengal', 'Education', 'Minister', 'Partha', 'Chatterjee', 'on', 'Tuesday', 'announced', 'that', 'school', 'for', 'class', '9', 'to', '12', 'will', 'reopen', 'from', 'February', '12', 'Chatterjee', 'said', 'the', 'consent', 'of', 'parent', 'would', 'be', 'mandatory', 'for', 'attending', 'physical', 'class', 'However', 'he', 'further', 'said', 'that', 'student', 'attendance', 'might', 'not', 'be', 'compulsory', 'adding', 'that', 'school', 'were', 'being', 'thoroughly', 'sanitised', 'at', 'regular', 'interval'])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words.lemmatize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('West', 'NNP'),\n",
       " ('Bengal', 'NNP'),\n",
       " ('Education', 'NNP'),\n",
       " ('Minister', 'NNP'),\n",
       " ('Partha', 'NNP'),\n",
       " ('Chatterjee', 'NNP'),\n",
       " ('on', 'IN'),\n",
       " ('Tuesday', 'NNP'),\n",
       " ('announced', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('schools', 'NNS'),\n",
       " ('for', 'IN'),\n",
       " ('classes', 'NNS'),\n",
       " ('9', 'CD'),\n",
       " ('to', 'TO'),\n",
       " ('12', 'CD'),\n",
       " ('will', 'MD'),\n",
       " ('reopen', 'VB'),\n",
       " ('from', 'IN'),\n",
       " ('February', 'NNP'),\n",
       " ('12', 'CD'),\n",
       " ('Chatterjee', 'NNP'),\n",
       " ('said', 'VBD'),\n",
       " ('the', 'DT'),\n",
       " ('consent', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('parents', 'NNS'),\n",
       " ('would', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('mandatory', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('attending', 'VBG'),\n",
       " ('physical', 'JJ'),\n",
       " ('classes', 'NNS'),\n",
       " ('However', 'RB'),\n",
       " ('he', 'PRP'),\n",
       " ('further', 'RB'),\n",
       " ('said', 'VBD'),\n",
       " ('that', 'IN'),\n",
       " ('students', 'NNS'),\n",
       " (\"'\", 'POS'),\n",
       " ('attendance', 'NN'),\n",
       " ('might', 'MD'),\n",
       " ('not', 'RB'),\n",
       " ('be', 'VB'),\n",
       " ('compulsory', 'NN'),\n",
       " ('adding', 'VBG'),\n",
       " ('that', 'IN'),\n",
       " ('schools', 'NNS'),\n",
       " ('were', 'VBD'),\n",
       " ('being', 'VBG'),\n",
       " ('thoroughly', 'RB'),\n",
       " ('sanitised', 'VBN'),\n",
       " ('at', 'IN'),\n",
       " ('regular', 'JJ'),\n",
       " ('intervals', 'NNS')]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "West Bengal Education Minister Partha Chatterjee Tuesday school class February Chatterjee consent parent class student attendance compulsory school interval "
     ]
    }
   ],
   "source": [
    "noun = list()\n",
    "for word, tag in blob.tags:\n",
    "    if tag=='NNP' or tag=='NNS' or tag=='NN':\n",
    "        noun.append(word.lemmatize())\n",
    "\n",
    "for n in noun:\n",
    "    print(n, end=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
