{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://stanza.run/bio\n",
    "https://pytorch.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting stanza\n",
      "  Downloading stanza-1.2-py3-none-any.whl (282 kB)\n",
      "Collecting torch>=1.3.0\n",
      "  Downloading torch-1.7.1-cp38-cp38-win_amd64.whl (184.0 MB)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza) (1.19.2)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza) (4.50.2)\n",
      "Collecting protobuf\n",
      "  Downloading protobuf-3.14.0-py2.py3-none-any.whl (173 kB)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza) (2.24.0)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
      "Requirement already satisfied: six>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf->stanza) (1.15.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->stanza) (2020.6.20)\n",
      "Installing collected packages: torch, protobuf, stanza\n",
      "Successfully installed protobuf-3.14.0 stanza-1.2 torch-1.7.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install stanza\n",
    "# pip install standfordnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/master/resources_1.2.0.json: 128kB [00:00, 9.82MB/s]\n",
      "2021-02-09 08:49:25 INFO: Downloading default packages for language: en (English)...\n",
      "Downloading http://nlp.stanford.edu/software/stanza/1.2.0/en/default.zip: 100%|█████| 411M/411M [03:04<00:00, 2.22MB/s]\n",
      "2021-02-09 08:52:40 INFO: Finished downloading models and saved to C:\\Users\\Gaurab\\stanza_resources.\n"
     ]
    }
   ],
   "source": [
    "# download a lib for perticular language\n",
    "# stanza.download('hi')    # Hindi\n",
    "# stanza.download('fr')    # French\n",
    "# stanza.download('ja')    # Japanese\n",
    "stanza.download('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-09 08:53:13 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-02-09 08:53:13 INFO: Use device: cpu\n",
      "2021-02-09 08:53:13 INFO: Loading: tokenize\n",
      "2021-02-09 08:53:13 INFO: Loading: pos\n",
      "2021-02-09 08:53:13 INFO: Loading: lemma\n",
      "2021-02-09 08:53:14 INFO: Loading: depparse\n",
      "2021-02-09 08:53:14 INFO: Loading: sentiment\n",
      "2021-02-09 08:53:15 INFO: Loading: ner\n",
      "2021-02-09 08:53:16 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# initialize English neural pipeline\n",
    "nlp = stanza.Pipeline('en')\n",
    "# nlp = stanza.Pipeline('en', processors='tokenize,lemma', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stanza.models.common.doc.Document"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run annotation over a sentence\n",
    "doc = nlp(\"Barack Obama was born in Hawaii, I was born in India.\")\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  [\n",
       "    {\n",
       "      \"id\": 1,\n",
       "      \"text\": \"Barack\",\n",
       "      \"lemma\": \"Barack\",\n",
       "      \"upos\": \"PROPN\",\n",
       "      \"xpos\": \"NNP\",\n",
       "      \"feats\": \"Number=Sing\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"nsubj:pass\",\n",
       "      \"misc\": \"start_char=0|end_char=6\",\n",
       "      \"ner\": \"B-PERSON\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 2,\n",
       "      \"text\": \"Obama\",\n",
       "      \"lemma\": \"Obama\",\n",
       "      \"upos\": \"PROPN\",\n",
       "      \"xpos\": \"NNP\",\n",
       "      \"feats\": \"Number=Sing\",\n",
       "      \"head\": 1,\n",
       "      \"deprel\": \"flat\",\n",
       "      \"misc\": \"start_char=7|end_char=12\",\n",
       "      \"ner\": \"E-PERSON\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 3,\n",
       "      \"text\": \"was\",\n",
       "      \"lemma\": \"be\",\n",
       "      \"upos\": \"AUX\",\n",
       "      \"xpos\": \"VBD\",\n",
       "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"aux:pass\",\n",
       "      \"misc\": \"start_char=13|end_char=16\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 4,\n",
       "      \"text\": \"born\",\n",
       "      \"lemma\": \"bear\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBN\",\n",
       "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
       "      \"head\": 0,\n",
       "      \"deprel\": \"root\",\n",
       "      \"misc\": \"start_char=17|end_char=21\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 5,\n",
       "      \"text\": \"in\",\n",
       "      \"lemma\": \"in\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"IN\",\n",
       "      \"head\": 6,\n",
       "      \"deprel\": \"case\",\n",
       "      \"misc\": \"start_char=22|end_char=24\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 6,\n",
       "      \"text\": \"Hawaii\",\n",
       "      \"lemma\": \"Hawaii\",\n",
       "      \"upos\": \"PROPN\",\n",
       "      \"xpos\": \"NNP\",\n",
       "      \"feats\": \"Number=Sing\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"obl\",\n",
       "      \"misc\": \"start_char=25|end_char=31\",\n",
       "      \"ner\": \"S-GPE\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 7,\n",
       "      \"text\": \",\",\n",
       "      \"lemma\": \",\",\n",
       "      \"upos\": \"PUNCT\",\n",
       "      \"xpos\": \",\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"punct\",\n",
       "      \"misc\": \"start_char=31|end_char=32\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 8,\n",
       "      \"text\": \"I\",\n",
       "      \"lemma\": \"I\",\n",
       "      \"upos\": \"PRON\",\n",
       "      \"xpos\": \"PRP\",\n",
       "      \"feats\": \"Case=Nom|Number=Sing|Person=1|PronType=Prs\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"nsubj:pass\",\n",
       "      \"misc\": \"start_char=33|end_char=34\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 9,\n",
       "      \"text\": \"was\",\n",
       "      \"lemma\": \"be\",\n",
       "      \"upos\": \"AUX\",\n",
       "      \"xpos\": \"VBD\",\n",
       "      \"feats\": \"Mood=Ind|Number=Sing|Person=3|Tense=Past|VerbForm=Fin\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"aux:pass\",\n",
       "      \"misc\": \"start_char=35|end_char=38\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 10,\n",
       "      \"text\": \"born\",\n",
       "      \"lemma\": \"bear\",\n",
       "      \"upos\": \"VERB\",\n",
       "      \"xpos\": \"VBN\",\n",
       "      \"feats\": \"Tense=Past|VerbForm=Part|Voice=Pass\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"parataxis\",\n",
       "      \"misc\": \"start_char=39|end_char=43\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 11,\n",
       "      \"text\": \"in\",\n",
       "      \"lemma\": \"in\",\n",
       "      \"upos\": \"ADP\",\n",
       "      \"xpos\": \"IN\",\n",
       "      \"head\": 12,\n",
       "      \"deprel\": \"case\",\n",
       "      \"misc\": \"start_char=44|end_char=46\",\n",
       "      \"ner\": \"O\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 12,\n",
       "      \"text\": \"India\",\n",
       "      \"lemma\": \"India\",\n",
       "      \"upos\": \"PROPN\",\n",
       "      \"xpos\": \"NNP\",\n",
       "      \"feats\": \"Number=Sing\",\n",
       "      \"head\": 10,\n",
       "      \"deprel\": \"obl\",\n",
       "      \"misc\": \"start_char=47|end_char=52\",\n",
       "      \"ner\": \"S-GPE\"\n",
       "    },\n",
       "    {\n",
       "      \"id\": 13,\n",
       "      \"text\": \".\",\n",
       "      \"lemma\": \".\",\n",
       "      \"upos\": \"PUNCT\",\n",
       "      \"xpos\": \".\",\n",
       "      \"head\": 4,\n",
       "      \"deprel\": \"punct\",\n",
       "      \"misc\": \"start_char=52|end_char=53\",\n",
       "      \"ner\": \"O\"\n",
       "    }\n",
       "  ]\n",
       "]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_ents', '_num_tokens', '_num_words', '_process_sentences', '_sentences', '_text', 'add_property', 'build_ents', 'entities', 'ents', 'from_serialized', 'get', 'get_mwt_expansions', 'iter_tokens', 'iter_words', 'num_tokens', 'num_words', 'sentences', 'set', 'set_mwt_expansions', 'text', 'to_dict', 'to_serialized']\n"
     ]
    }
   ],
   "source": [
    "print(dir(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Barack Obama was born in Hawaii, I was born in India.\n"
     ]
    }
   ],
   "source": [
    "for i in doc.sentences:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Sentence1 tokens ================\n",
      "id: (1,)\ttext: Barack\n",
      "id: (2,)\ttext: Obama\n",
      "id: (3,)\ttext: was\n",
      "id: (4,)\ttext: born\n",
      "id: (5,)\ttext: in\n",
      "id: (6,)\ttext: Hawaii\n",
      "id: (7,)\ttext: ,\n",
      "id: (8,)\ttext: I\n",
      "id: (9,)\ttext: was\n",
      "id: (10,)\ttext: born\n",
      "id: (11,)\ttext: in\n",
      "id: (12,)\ttext: India\n",
      "id: (13,)\ttext: .\n"
     ]
    }
   ],
   "source": [
    "for i , sentence in enumerate(doc.sentences):\n",
    "    print(f'==============Sentence{i+1} tokens ================')\n",
    "    print(*[f'id: {token.id}\\ttext: {token.text}'for token in sentence.tokens] , sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2 3 4 5\n",
      "1 2 3 4 5\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3,4,5]\n",
    "print(a[0], a[1], a[2], a[3], a[4])\n",
    "print(*a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Sentence1 tokens ================\n",
      "id: 1\ttext: Barack\tupos:PROPN\n",
      "id: 2\ttext: Obama\tupos:PROPN\n",
      "id: 3\ttext: was\tupos:AUX\n",
      "id: 4\ttext: born\tupos:VERB\n",
      "id: 5\ttext: in\tupos:ADP\n",
      "id: 6\ttext: Hawaii\tupos:PROPN\n",
      "id: 7\ttext: ,\tupos:PUNCT\n",
      "id: 8\ttext: I\tupos:PRON\n",
      "id: 9\ttext: was\tupos:AUX\n",
      "id: 10\ttext: born\tupos:VERB\n",
      "id: 11\ttext: in\tupos:ADP\n",
      "id: 12\ttext: India\tupos:PROPN\n",
      "id: 13\ttext: .\tupos:PUNCT\n"
     ]
    }
   ],
   "source": [
    "for i , sentence in enumerate(doc.sentences):\n",
    "    print(f'==============Sentence{i+1} tokens ================')\n",
    "    print(*[f'id: {token.id}\\ttext: {token.text}\\tupos:{token.upos}'for token in sentence.words] , sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Sentence1 tokens ================\n",
      "id: 1\ttext: Barack\tlemma:Barack\n",
      "id: 2\ttext: Obama\tlemma:Obama\n",
      "id: 3\ttext: was\tlemma:be\n",
      "id: 4\ttext: born\tlemma:bear\n",
      "id: 5\ttext: in\tlemma:in\n",
      "id: 6\ttext: Hawaii\tlemma:Hawaii\n",
      "id: 7\ttext: ,\tlemma:,\n",
      "id: 8\ttext: I\tlemma:I\n",
      "id: 9\ttext: was\tlemma:be\n",
      "id: 10\ttext: born\tlemma:bear\n",
      "id: 11\ttext: in\tlemma:in\n",
      "id: 12\ttext: India\tlemma:India\n",
      "id: 13\ttext: .\tlemma:.\n"
     ]
    }
   ],
   "source": [
    "# lemmatization\n",
    "for i , sentence in enumerate(doc.sentences):\n",
    "    print(f'==============Sentence{i+1} tokens ================')\n",
    "    print(*[f'id: {token.id}\\ttext: {token.text}\\tlemma:{token.lemma}'for token in sentence.words] , sep='\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============Sentence1 tokens ================\n",
      "id: (1,)\ttext: Barack\tNER:B-PERSON\n",
      "id: (2,)\ttext: Obama\tNER:E-PERSON\n",
      "id: (3,)\ttext: was\tNER:O\n",
      "id: (4,)\ttext: born\tNER:O\n",
      "id: (5,)\ttext: in\tNER:O\n",
      "id: (6,)\ttext: Hawaii\tNER:S-GPE\n",
      "id: (7,)\ttext: ,\tNER:O\n",
      "id: (8,)\ttext: I\tNER:O\n",
      "id: (9,)\ttext: was\tNER:O\n",
      "id: (10,)\ttext: born\tNER:O\n",
      "id: (11,)\ttext: in\tNER:O\n",
      "id: (12,)\ttext: India\tNER:S-GPE\n",
      "id: (13,)\ttext: .\tNER:O\n"
     ]
    }
   ],
   "source": [
    "# NER\n",
    "for i , sentence in enumerate(doc.sentences):\n",
    "    print(f'==============Sentence{i+1} tokens ================')\n",
    "    print(*[f'id: {token.id}\\ttext: {token.text}\\tNER:{token.ner}'for token in sentence.tokens] , sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy_stanza in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: spacy<3.0.0,>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy_stanza) (2.3.5)\n",
      "Requirement already satisfied: stanza<1.2.0,>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy_stanza) (1.1.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (1.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (50.3.1.post20201107)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (0.7.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (2.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (1.19.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (2.24.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (4.50.2)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (3.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (1.0.5)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<3.0.0,>=2.1.0->spacy_stanza) (7.4.5)\n",
      "Requirement already satisfied: torch>=1.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza<1.2.0,>=1.0.0->spacy_stanza) (1.7.1)\n",
      "Requirement already satisfied: protobuf in c:\\programdata\\anaconda3\\lib\\site-packages (from stanza<1.2.0,>=1.0.0->spacy_stanza) (3.14.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_stanza) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_stanza) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_stanza) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.1.0->spacy_stanza) (2.10)\n",
      "Requirement already satisfied: typing-extensions in c:\\programdata\\anaconda3\\lib\\site-packages (from torch>=1.3.0->stanza<1.2.0,>=1.0.0->spacy_stanza) (3.7.4.3)Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: six>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf->stanza<1.2.0,>=1.0.0->spacy_stanza) (1.15.0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_stanza import StanzaLanguage\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-09 09:20:56 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-02-09 09:20:56 INFO: Use device: cpu\n",
      "2021-02-09 09:20:56 INFO: Loading: tokenize\n",
      "2021-02-09 09:20:57 INFO: Loading: pos\n",
      "2021-02-09 09:20:57 INFO: Loading: lemma\n",
      "2021-02-09 09:20:57 INFO: Loading: depparse\n",
      "2021-02-09 09:20:58 INFO: Loading: sentiment\n",
      "2021-02-09 09:20:58 INFO: Loading: ner\n",
      "2021-02-09 09:20:59 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "# wrap stanza with spacy\n",
    "abc = stanza.Pipeline('en', use_gpu=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanzaLanguage(abc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('Barack Obama was born in Hawaii, I was born in India.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"4f18924b34c94af998c839e44446eb96-0\" class=\"displacy\" width=\"1975\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Barack</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">Obama</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">born</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Hawaii,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">I</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">was</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">born</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">in</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">India.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,89.5 570.0,89.5 570.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj:pass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux:pass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-3\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-4\" stroke-width=\"2px\" d=\"M595,352.0 C595,177.0 915.0,177.0 915.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M915.0,354.0 L923.0,342.0 907.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-5\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,177.0 1440.0,177.0 1440.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj:pass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-6\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux:pass</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1295,354.0 L1287,342.0 1303,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-7\" stroke-width=\"2px\" d=\"M595,352.0 C595,2.0 1450.0,2.0 1450.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">parataxis</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1450.0,354.0 L1458.0,342.0 1442.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-8\" stroke-width=\"2px\" d=\"M1645,352.0 C1645,264.5 1785.0,264.5 1785.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1645,354.0 L1637,342.0 1653,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4f18924b34c94af998c839e44446eb96-0-9\" stroke-width=\"2px\" d=\"M1470,352.0 C1470,177.0 1790.0,177.0 1790.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4f18924b34c94af998c839e44446eb96-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1790.0,354.0 L1798.0,342.0 1782.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
